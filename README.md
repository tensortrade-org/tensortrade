<p align="center">
  <img src="docs/source/_static/logo.jpg" width="200" alt="TensorTrade Logo">
</p>

# TensorTrade

**Train RL agents to trade. Can they beat Buy-and-Hold?**

[![Tests](https://github.com/tensortrade-org/tensortrade/actions/workflows/tests.yml/badge.svg)](https://github.com/tensortrade-org/tensortrade/actions/workflows/tests.yml)
[![Documentation Status](https://readthedocs.org/projects/tensortrade/badge/?version=latest)](https://tensortrade.org)
[![Apache License](https://img.shields.io/github/license/tensortrade-org/tensortrade.svg?color=brightgreen)](http://www.apache.org/licenses/LICENSE-2.0)
[![Discord](https://img.shields.io/discord/592446624882491402.svg?color=brightgreen)](https://discord.gg/ZZ7BGWh)
[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/release/python-3120/)

TensorTrade is an open-source Python framework for building, training, and evaluating reinforcement learning agents for algorithmic trading. The framework provides composable components for environments, action schemes, reward functions, and data feeds that can be combined to create custom trading systems.

## Quick Start

```bash
# Requires Python 3.12+
python3.12 -m venv tensortrade-env && source tensortrade-env/bin/activate
pip install -e .

# For training with Ray/RLlib (recommended)
pip install -r examples/requirements.txt

# Run training
python examples/training/train_simple.py
```

## Documentation & Tutorials

ðŸ“š **[Tutorial Index](docs/tutorials/index.md)** â€” Start here for the complete learning curriculum.

### Foundations
- [The Three Pillars](docs/tutorials/01-foundations/01-three-pillars.md) â€” RL + Trading + Data concepts
- [Architecture](docs/tutorials/01-foundations/02-architecture.md) â€” How components work together
- [Your First Run](docs/tutorials/01-foundations/03-your-first-run.md) â€” Run and understand output

### Domain Knowledge
- [Trading for RL Practitioners](docs/tutorials/02-domains/track-a-trading-for-rl/01-trading-basics.md)
- [RL for Traders](docs/tutorials/02-domains/track-b-rl-for-traders/01-rl-fundamentals.md)
- [Common Failures](docs/tutorials/02-domains/track-b-rl-for-traders/02-common-failures.md) â€” Critical pitfalls to avoid
- [Full Introduction](docs/tutorials/02-domains/track-c-full-intro/README.md) â€” New to both domains

### Core Components
- [Action Schemes](docs/tutorials/03-components/01-action-schemes.md) â€” BSH and order execution
- [Reward Schemes](docs/tutorials/03-components/02-reward-schemes.md) â€” Why PBR works
- [Observers & Feeds](docs/tutorials/03-components/03-observers-feeds.md) â€” Feature engineering

### Training
- [First Training](docs/tutorials/04-training/01-first-training.md) â€” Train with Ray RLlib
- [Ray RLlib Deep Dive](docs/tutorials/04-training/02-ray-rllib.md) â€” Configuration options
- [Optuna Optimization](docs/tutorials/04-training/03-optuna.md) â€” Hyperparameter tuning

### Advanced Topics
- [Overfitting](docs/tutorials/05-advanced/01-overfitting.md) â€” Detection and prevention
- [Commission Analysis](docs/tutorials/05-advanced/02-commission.md) â€” Key research findings
- [Walk-Forward Validation](docs/tutorials/05-advanced/03-walk-forward.md) â€” Proper evaluation

### Additional Resources
- [Experiments Log](docs/EXPERIMENTS.md) â€” Full research documentation
- [Environment Setup](docs/ENVIRONMENT_SETUP.md) â€” Detailed installation guide
- [API Reference](https://www.tensortrade.org/en/latest/)

---

## Research Findings

We conducted extensive experiments training PPO agents on BTC/USD. Key results:

| Configuration | Test P&L | vs Buy-and-Hold |
|---------------|----------|-----------------|
| Agent (0% commission) | +$239 | +$594 |
| Agent (0.1% commission) | -$650 | -$295 |
| Buy-and-Hold | -$355 | â€” |

The agent demonstrates directional prediction capability at zero commission. The primary challenge is trading frequencyâ€”commission costs currently exceed prediction profits. See [EXPERIMENTS.md](docs/EXPERIMENTS.md) for methodology and detailed analysis.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TradingEnv                               â”‚
â”‚                                                                 â”‚
â”‚   Observer â”€â”€â”€â”€â”€â”€> Agent â”€â”€â”€â”€â”€â”€> ActionScheme â”€â”€â”€â”€â”€â”€> Portfolio â”‚
â”‚   (features)      (policy)      (BSH/Orders)        (wallets)  â”‚
â”‚       ^                                                  â”‚      â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RewardScheme <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                        (PBR)                                    â”‚
â”‚                                                                 â”‚
â”‚   DataFeed â”€â”€â”€â”€â”€â”€> Exchange â”€â”€â”€â”€â”€â”€> Broker â”€â”€â”€â”€â”€â”€> Trades       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Component | Purpose | Default |
|-----------|---------|---------|
| ActionScheme | Converts agent output to orders | BSH (Buy/Sell/Hold) |
| RewardScheme | Computes learning signal | PBR (Position-Based Returns) |
| Observer | Generates observations | Windowed features |
| Portfolio | Manages wallets and positions | USD + BTC |
| Exchange | Simulates execution | Configurable commission |

---

## Training Scripts

| Script | Description |
|--------|-------------|
| `examples/training/train_simple.py` | Basic demo with wallet tracking |
| `examples/training/train_ray_long.py` | Distributed training with Ray RLlib |
| `examples/training/train_optuna.py` | Hyperparameter optimization |
| `examples/training/train_best.py` | Best configuration from experiments |

---

## Installation

**Requirements:** Python 3.11 or 3.12

```bash
# Create environment
python3.12 -m venv tensortrade-env
source tensortrade-env/bin/activate  # Windows: tensortrade-env\Scripts\activate

# Install
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .

# Verify
pytest tests/tensortrade/unit -v

# Training dependencies (optional)
pip install -r examples/requirements.txt
```

See [ENVIRONMENT_SETUP.md](docs/ENVIRONMENT_SETUP.md) for platform-specific instructions and troubleshooting.

### Docker

```bash
make run-notebook  # Jupyter
make run-docs      # Documentation
make run-tests     # Test suite
```

---

## Project Structure

```
tensortrade/
â”œâ”€â”€ tensortrade/           # Core library
â”‚   â”œâ”€â”€ env/              # Trading environments
â”‚   â”œâ”€â”€ feed/             # Data pipeline
â”‚   â”œâ”€â”€ oms/              # Order management
â”‚   â””â”€â”€ data/             # Data fetching
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ training/         # Training scripts
â”‚   â””â”€â”€ notebooks/        # Jupyter tutorials
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ tutorials/        # Learning curriculum
â”‚   â””â”€â”€ EXPERIMENTS.md    # Research log
â””â”€â”€ tests/
```

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| "No stream satisfies selector" | Update to v1.0.4-dev1+ |
| Ray installation fails | Run `pip install --upgrade pip` first |
| NumPy version conflict | `pip install "numpy>=1.26.4,<2.0"` |
| TensorFlow CUDA issues | `pip install tensorflow[and-cuda]>=2.15.1` |

---

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

Priority areas:
1. Trading frequency reduction (position sizing, holding periods)
2. Commission-aware reward schemes
3. Alternative action spaces

---

## Community

- [Discord](https://discord.gg/ZZ7BGWh)
- [GitHub Issues](https://github.com/notadamking/tensortrade/issues)
- [Documentation](https://www.tensortrade.org/)

---

## License

[Apache 2.0](LICENSE)
