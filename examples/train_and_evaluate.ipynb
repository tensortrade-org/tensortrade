{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install TensorTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensortrade'...\n",
      "remote: Enumerating objects: 10936, done.\u001b[K\n",
      "remote: Counting objects: 100% (765/765), done.\u001b[K\n",
      "remote: Compressing objects: 100% (533/533), done.\u001b[K\n",
      "remote: Total 10936 (delta 422), reused 467 (delta 216), pack-reused 10171\u001b[K\n",
      "Receiving objects: 100% (10936/10936), 63.87 MiB | 5.47 MiB/s, done.\n",
      "Resolving deltas: 100% (7176/7176), done.\n",
      "/examples/tensortrade\n",
      "Obtaining file:///examples/tensortrade\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (1.21.3)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (1.4.1)\n",
      "Requirement already satisfied: gym>=0.15.7 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (0.21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (6.0)\n",
      "Requirement already satisfied: stochastic>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (0.6.0)\n",
      "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (2.7.0)\n",
      "Requirement already satisfied: ipython>=7.12.0 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (8.0.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (3.5.1)\n",
      "Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from tensortrade==1.0.4.dev1) (5.6.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.15.7->tensortrade==1.0.4.dev1) (2.0.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (60.9.1)\n",
      "Requirement already satisfied: black in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (22.1.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.18.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.12.0->tensortrade==1.0.4.dev1) (3.0.28)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (4.29.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.1.1->tensortrade==1.0.4.dev1) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.0->tensortrade==1.0.4.dev1) (2021.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.5.0->tensortrade==1.0.4.dev1) (8.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from plotly>=4.5.0->tensortrade==1.0.4.dev1) (1.14.0)\n",
      "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.8/dist-packages (from stochastic>=0.6.0->tensortrade==1.0.4.dev1) (1.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (3.10.0.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (3.5.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.13.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.21.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (3.19.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (12.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.34.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.41.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.2.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black->ipython>=7.12.0->tensortrade==1.0.4.dev1) (8.0.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black->ipython>=7.12.0->tensortrade==1.0.4.dev1) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from black->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.9.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black->ipython>=7.12.0->tensortrade==1.0.4.dev1) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.4.3)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.8.2)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=7.12.0->tensortrade==1.0.4.dev1) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=7.12.0->tensortrade==1.0.4.dev1) (2.0.5)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (1.25.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tensortrade==1.0.4.dev1) (3.1.1)\n",
      "Installing collected packages: tensortrade\n",
      "  Attempting uninstall: tensortrade\n",
      "    Found existing installation: tensortrade 1.0.4.dev1\n",
      "    Uninstalling tensortrade-1.0.4.dev1:\n",
      "      Successfully uninstalled tensortrade-1.0.4.dev1\n",
      "  Running setup.py develop for tensortrade\n",
      "Successfully installed tensortrade\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install git+https://github.com/abstractguy/tensortrade.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (7.0.0)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.12.10)\n",
      "Requirement already satisfied: feature_engine in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
      "Requirement already satisfied: tensorflow-probability==0.15.0 in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (1.21.3)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (0.1.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability==0.15.0) (1.14.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (0.4.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (2.0.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability==0.15.0) (0.15.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.26)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.5.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2021.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.2->feature_engine) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.2->feature_engine) (1.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=21.3->statsmodels>=0.11.1->feature_engine) (3.0.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install pyarrow wandb feature_engine \"tensorflow-probability==0.15.0\" opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps: int = 1000\n",
    "n_episodes: int = 10\n",
    "save_every: int = None\n",
    "window_size: int = 30\n",
    "memory_capacity: int = n_steps * 10\n",
    "save_path: str = 'agents/'\n",
    "discount_factor: float = 0.95\n",
    "learning_rate: float = 0.01\n",
    "eps_start: float = 0.9\n",
    "eps_end: float =  0.05\n",
    "eps_decay_steps: int = n_steps\n",
    "update_target_every: int = 1000\n",
    "render_interval: int = n_steps // 10\n",
    "n_bins: int = 5             # Number of bins to partition the dataset evenly in order to evaluate class sparsity.\n",
    "seed: int = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensortrade.data.cdd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensortrade\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcdd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CryptoDataDownload\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensortrade.data.cdd'"
     ]
    }
   ],
   "source": [
    "from tensortrade.data.cdd import CryptoDataDownload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['volume'] = np.int64(df['volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d %I:%M %p')\n",
    "    return df\n",
    "\n",
    "def fetch_data():\n",
    "    cdd = CryptoDataDownload()\n",
    "    bitfinex_data = cdd.fetch(\"Bitfinex\", \"USD\", \"BTC\", \"1h\")\n",
    "    bitfinex_data = bitfinex_data[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    bitfinex_data = prepare_data(bitfinex_data)\n",
    "    return bitfinex_data\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv('data/' + filename, skiprows=1)\n",
    "    df.drop(columns=['symbol', 'volume_btc'], inplace=True)\n",
    "\n",
    "    # Fix timestamp from \"2019-10-17 09-AM\" to \"2019-10-17 09-00-00 AM\"\n",
    "    df['date'] = df['date'].str[:14] + '00-00 ' + df['date'].str[-2:]\n",
    "\n",
    "    return prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features for the feed module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ta as ta1\n",
    "import pandas_ta as ta\n",
    "\n",
    "import quantstats as qs\n",
    "qs.extend_pandas()\n",
    "\n",
    "def fix_dataset_inconsistencies(dataframe, fill_value=None):\n",
    "    dataframe = dataframe.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "    # This is done to avoid filling middle holes with backfilling.\n",
    "    if fill_value is None:\n",
    "        dataframe.iloc[0,:] = \\\n",
    "            dataframe.apply(lambda column: column.iloc[column.first_valid_index()], axis='index')\n",
    "    else:\n",
    "        dataframe.iloc[0,:] = \\\n",
    "            dataframe.iloc[0,:].fillna(fill_value)\n",
    "\n",
    "    return dataframe.fillna(axis='index', method='pad').dropna(axis='columns')\n",
    "\n",
    "def rsi(price: 'pd.Series[pd.Float64Dtype]', period: float) -> 'pd.Series[pd.Float64Dtype]':\n",
    "    r = price.diff()\n",
    "    upside = np.minimum(r, 0).abs()\n",
    "    downside = np.maximum(r, 0).abs()\n",
    "    rs = upside.ewm(alpha=1 / period).mean() / downside.ewm(alpha=1 / period).mean()\n",
    "    return 100*(1 - (1 + rs) ** -1)\n",
    "\n",
    "def macd(price: 'pd.Series[pd.Float64Dtype]', fast: float, slow: float, signal: float) -> 'pd.Series[pd.Float64Dtype]':\n",
    "    fm = price.ewm(span=fast, adjust=False).mean()\n",
    "    sm = price.ewm(span=slow, adjust=False).mean()\n",
    "    md = fm - sm\n",
    "    signal = md - md.ewm(span=signal, adjust=False).mean()\n",
    "    return signal\n",
    "\n",
    "def generate_all_default_quantstats_features(data):\n",
    "    excluded_indicators = [\n",
    "        'compare',\n",
    "        'greeks',\n",
    "        'information_ratio',\n",
    "        'omega',\n",
    "        'r2',\n",
    "        'r_squared',\n",
    "        'rolling_greeks',\n",
    "        'warn',\n",
    "    ]\n",
    "    \n",
    "    indicators_list = [f for f in dir(qs.stats) if f[0] != '_' and f not in excluded_indicators]\n",
    "    \n",
    "    df = data.copy()\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "\n",
    "    for indicator_name in indicators_list:\n",
    "        try:\n",
    "            #print(indicator_name)\n",
    "            indicator = qs.stats.__dict__[indicator_name](df['close'])\n",
    "            if isinstance(indicator, pd.Series):\n",
    "                indicator = indicator.to_frame(name=indicator_name)\n",
    "                df = pd.concat([df, indicator], axis='columns')\n",
    "        except (pd.errors.InvalidIndexError, ValueError):\n",
    "            pass\n",
    "\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def generate_features(data):\n",
    "    # Automatically-generated using pandas_ta\n",
    "    df = data.copy()\n",
    "\n",
    "    strategies = ['candles', \n",
    "                  'cycles', \n",
    "                  'momentum', \n",
    "                  'overlap', \n",
    "                  'performance', \n",
    "                  'statistics', \n",
    "                  'trend', \n",
    "                  'volatility', \n",
    "                  'volume']\n",
    "\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "\n",
    "    cores = os.cpu_count()\n",
    "    df.ta.cores = cores\n",
    "\n",
    "    for strategy in strategies:\n",
    "        df.ta.study(strategy, exclude=['kvo'])\n",
    "\n",
    "    df = df.set_index('date')\n",
    "\n",
    "    # Generate all default indicators from ta library\n",
    "    ta1.add_all_ta_features(data, \n",
    "                            'open', \n",
    "                            'high', \n",
    "                            'low', \n",
    "                            'close', \n",
    "                            'volume', \n",
    "                            fillna=True)\n",
    "\n",
    "    # Naming convention across most technical indicator libraries\n",
    "    data = data.rename(columns={'open': 'Open', \n",
    "                                'high': 'High', \n",
    "                                'low': 'Low', \n",
    "                                'close': 'Close', \n",
    "                                'volume': 'Volume'})\n",
    "    data = data.set_index('date')\n",
    "\n",
    "    # Custom indicators\n",
    "    features = pd.DataFrame.from_dict({\n",
    "        'prev_open': data['Open'].shift(1),\n",
    "        'prev_high': data['High'].shift(1),\n",
    "        'prev_low': data['Low'].shift(1),\n",
    "        'prev_close': data['Close'].shift(1),\n",
    "        'prev_volume': data['Volume'].shift(1),\n",
    "        'vol_5': data['Close'].rolling(window=5).std().abs(),\n",
    "        'vol_10': data['Close'].rolling(window=10).std().abs(),\n",
    "        'vol_20': data['Close'].rolling(window=20).std().abs(),\n",
    "        'vol_30': data['Close'].rolling(window=30).std().abs(),\n",
    "        'vol_50': data['Close'].rolling(window=50).std().abs(),\n",
    "        'vol_60': data['Close'].rolling(window=60).std().abs(),\n",
    "        'vol_100': data['Close'].rolling(window=100).std().abs(),\n",
    "        'vol_200': data['Close'].rolling(window=200).std().abs(),\n",
    "        'ma_5': data['Close'].rolling(window=5).mean(),\n",
    "        'ma_10': data['Close'].rolling(window=10).mean(),\n",
    "        'ma_20': data['Close'].rolling(window=20).mean(),\n",
    "        'ma_30': data['Close'].rolling(window=30).mean(),\n",
    "        'ma_50': data['Close'].rolling(window=50).mean(),\n",
    "        'ma_60': data['Close'].rolling(window=60).mean(),\n",
    "        'ma_100': data['Close'].rolling(window=100).mean(),\n",
    "        'ma_200': data['Close'].rolling(window=200).mean(),\n",
    "        'ema_5': ta1.trend.ema_indicator(data['Close'], window=5, fillna=True),\n",
    "        'ema_10': ta1.trend.ema_indicator(data['Close'], window=10, fillna=True),\n",
    "        'ema_20': ta1.trend.ema_indicator(data['Close'], window=20, fillna=True),\n",
    "        'ema_60': ta1.trend.ema_indicator(data['Close'], window=60, fillna=True),\n",
    "        'ema_64': ta1.trend.ema_indicator(data['Close'], window=64, fillna=True),\n",
    "        'ema_120': ta1.trend.ema_indicator(data['Close'], window=120, fillna=True),\n",
    "        'lr_open': np.log(data['Open']).diff().fillna(0),\n",
    "        'lr_high': np.log(data['High']).diff().fillna(0),\n",
    "        'lr_low': np.log(data['Low']).diff().fillna(0),\n",
    "        'lr_close': np.log(data['Close']).diff().fillna(0),\n",
    "        'r_volume': data['Close'].diff().fillna(0),\n",
    "        'rsi_5': rsi(data['Close'], period=5),\n",
    "        'rsi_10': rsi(data['Close'], period=10),\n",
    "        'rsi_100': rsi(data['Close'], period=100),\n",
    "        'rsi_7': rsi(data['Close'], period=7),\n",
    "        'rsi_28': rsi(data['Close'], period=28),\n",
    "        'rsi_6': rsi(data['Close'], period=6),\n",
    "        'rsi_14': rsi(data['Close'], period=14),\n",
    "        'rsi_26': rsi(data['Close'], period=24),\n",
    "        'macd_normal': macd(data['Close'], fast=12, slow=26, signal=9),\n",
    "        'macd_short': macd(data['Close'], fast=10, slow=50, signal=5),\n",
    "        'macd_long': macd(data['Close'], fast=200, slow=100, signal=50),\n",
    "    })\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, features], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    # Revert naming convention\n",
    "    data = data.rename(columns={'Open': 'open', \n",
    "                                'High': 'high', \n",
    "                                'Low': 'low', \n",
    "                                'Close': 'close', \n",
    "                                'Volume': 'volume'})\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, df], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # Generate all default quantstats features\n",
    "    df_quantstats = generate_all_default_quantstats_features(data)\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, df_quantstats], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    # A lot of indicators generate NaNs at the beginning of DataFrames, so remove them\n",
    "    data = data.iloc[200:]\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data = fix_dataset_inconsistencies(data, fill_value=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_features(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['PCTRET_1', \n",
    "                          'LOGRET_1', \n",
    "                          'lr_close', \n",
    "                          'others_dr', \n",
    "                          'others_dlr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove features with low variance before splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0.0)\n",
    "date = data[['date']].copy()\n",
    "data = data.drop(columns=['date'])\n",
    "sel.fit(data)\n",
    "data[data.columns[sel.get_support(indices=True)]]\n",
    "data = pd.concat([date, data], axis='columns')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.copy()\n",
    "    y = X['close'].pct_change()\n",
    "\n",
    "    X_train_test, X_valid, y_train_test, y_valid = \\\n",
    "        train_test_split(data, data['close'].pct_change(), train_size=0.67, test_size=0.33, shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_train_test, y_train_test, train_size=0.50, test_size=0.50, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = \\\n",
    "    split_data(data)\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "train_csv = os.path.join(cwd, 'train.csv')\n",
    "test_csv = os.path.join(cwd, 'test.csv')\n",
    "valid_csv = os.path.join(cwd, 'valid.csv')\n",
    "X_train.to_csv(train_csv, index=False)\n",
    "X_test.to_csv(test_csv, index=False)\n",
    "X_valid.to_csv(valid_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "def estimate_outliers(data):\n",
    "    return iqr(data) * 1.5\n",
    "\n",
    "def estimate_percent_gains(data, column='close'):\n",
    "    returns = get_returns(data, column=column)\n",
    "    gains = estimate_outliers(returns)\n",
    "    return gains\n",
    "\n",
    "def get_returns(data, column='close'):\n",
    "    return fix_dataset_inconsistencies(data[[column]].pct_change(), fill_value=0)\n",
    "\n",
    "def precalculate_ground_truths(data, column='close', threshold=None):\n",
    "    returns = get_returns(data, column=column)\n",
    "    gains = estimate_outliers(returns) if threshold is None else threshold\n",
    "    binary_gains = (returns[column] > gains).astype(int)\n",
    "    return binary_gains\n",
    "\n",
    "def is_null(data):\n",
    "    return data.isnull().sum().sum() > 0\n",
    "\n",
    "def is_sparse(data, column='close'):\n",
    "    binary_gains = precalculate_ground_truths(data, column=column)\n",
    "    bins = [n * (binary_gains.shape[0] // n_bins) for n in range(n_bins)]\n",
    "    bins += [binary_gains.shape[0]]\n",
    "    bins = [binary_gains.iloc[bins[n]:bins[n + 1]] for n in range(n_bins)]\n",
    "    return all([bin.astype(bool).any() for bin in bins])\n",
    "\n",
    "def is_data_predictible(data, column):\n",
    "    return not is_null(data) & is_sparse(data, column)\n",
    "\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate outlier sparsity of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(get_returns(data, column='close'))\n",
    "plt.show()\n",
    "is_data_predictible(data, 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of the dataset generating rewards (keep between 5% to 15% or just rely on is_data_predictible())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(precalculate_ground_truths(data, column='close').iloc[:1000])\n",
    "plt.show()\n",
    "percent_rewardable = str(round(100 + precalculate_ground_truths(data, column='close').value_counts().pct_change().iloc[-1] * 100, 2)) + '%'\n",
    "print(percent_rewardable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold to pass to AnomalousProfit reward scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test = pd.concat([X_train, X_test], axis='index')\n",
    "#threshold = estimate_percent_gains(X_train_test, 'close')\n",
    "threshold = estimate_percent_gains(X_train, 'close')\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement basic feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            random_state=seed, \n",
    "                            n_jobs=6)\n",
    "\n",
    "sel = SelectBySingleFeaturePerformance(variables=None, \n",
    "                                       estimator=rf, \n",
    "                                       scoring=\"roc_auc\", \n",
    "                                       cv=5, \n",
    "                                       threshold=0.65)\n",
    "\n",
    "sel.fit(X_train, precalculate_ground_truths(X_train, column='close'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_performance = pd.Series(sel.feature_performance_).sort_values(ascending=False)\n",
    "feature_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_performance.plot.bar(figsize=(20, 5))\n",
    "plt.title('Performance of ML models trained with individual features')\n",
    "plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = sel.features_to_drop_\n",
    "features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(set(features_to_drop) - set(['open', 'high', 'low', 'close', 'volume']))\n",
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "X_valid = X_valid.drop(columns=to_drop)\n",
    "\n",
    "X_train.shape, X_test.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the dataset subsets to make the model converge faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "scaler_type = MinMaxScaler\n",
    "\n",
    "def get_feature_scalers(X, scaler_type=scaler_type):\n",
    "    scalers = []\n",
    "    for name in list(X.columns[X.columns != 'date']):\n",
    "        scalers.append(scaler_type().fit(X[name].values.reshape(-1, 1)))\n",
    "    return scalers\n",
    "\n",
    "def get_scaler_transforms(X, scalers):\n",
    "    X_scaled = []\n",
    "    for name, scaler in zip(list(X.columns[X.columns != 'date']), scalers):\n",
    "        X_scaled.append(scaler.transform(X[name].values.reshape(-1, 1)))\n",
    "    X_scaled = pd.concat([pd.DataFrame(column, columns=[name]) for name, column in \\\n",
    "                          zip(list(X.columns[X.columns != 'date']), X_scaled)], axis='columns')\n",
    "    return X_scaled\n",
    "\n",
    "def normalize_data(X_train, X_test, X_valid):\n",
    "    X_train_test = pd.concat([X_train, X_test], axis='index')\n",
    "    X_train_test_valid = pd.concat([X_train_test, X_valid], axis='index')\n",
    "\n",
    "    X_train_test_dates = X_train_test[['date']]\n",
    "    X_train_test_valid_dates = X_train_test_valid[['date']]\n",
    "\n",
    "    X_train_test = X_train_test.drop(columns=['date'])\n",
    "    X_train_test_valid = X_train_test_valid.drop(columns=['date'])\n",
    "\n",
    "    train_test_scalers = \\\n",
    "        get_feature_scalers(X_train_test, \n",
    "                            scaler_type=scaler_type)\n",
    "    train_test_valid_scalers = \\\n",
    "        get_feature_scalers(X_train_test_valid, \n",
    "                            scaler_type=scaler_type)\n",
    "\n",
    "    X_train_test_scaled = \\\n",
    "        get_scaler_transforms(X_train_test, \n",
    "                              train_test_scalers)\n",
    "    X_train_test_valid_scaled = \\\n",
    "        get_scaler_transforms(X_train_test_valid, \n",
    "                              train_test_scalers)\n",
    "    X_train_test_valid_scaled_leaking = \\\n",
    "        get_scaler_transforms(X_train_test_valid, \n",
    "                              train_test_valid_scalers)\n",
    "\n",
    "    X_train_test_scaled = \\\n",
    "        pd.concat([X_train_test_dates, \n",
    "                   X_train_test_scaled], \n",
    "                  axis='columns')\n",
    "    X_train_test_valid_scaled = \\\n",
    "        pd.concat([X_train_test_valid_dates, \n",
    "                   X_train_test_valid_scaled], \n",
    "                  axis='columns')\n",
    "    X_train_test_valid_scaled_leaking = \\\n",
    "        pd.concat([X_train_test_valid_dates, \n",
    "                   X_train_test_valid_scaled_leaking], \n",
    "                  axis='columns')\n",
    "\n",
    "    X_train_scaled = X_train_test_scaled.iloc[:X_train.shape[0]]\n",
    "    X_test_scaled = X_train_test_scaled.iloc[X_train.shape[0]:]\n",
    "    X_valid_scaled = X_train_test_valid_scaled.iloc[X_train_test.shape[0]:]\n",
    "    X_valid_scaled_leaking = X_train_test_valid_scaled_leaking.iloc[X_train_test.shape[0]:]\n",
    "\n",
    "    return (train_test_scalers, \n",
    "            train_test_valid_scalers, \n",
    "            X_train_scaled, \n",
    "            X_test_scaled, \n",
    "            X_valid_scaled, \n",
    "            X_valid_scaled_leaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_scalers, train_test_valid_scalers, X_train_scaled, X_test_scaled, X_valid_scaled, X_valid_scaled_leaking = \\\n",
    "    normalize_data(X_train, X_test, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are more useful features than OHLCV to use for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_scaled.drop(columns=['open', \n",
    "                                              'high', \n",
    "                                              'low', \n",
    "                                              'close', \n",
    "                                              'volume'])\n",
    "\n",
    "X_test_scaled = X_test_scaled.drop(columns=['open', \n",
    "                                            'high', \n",
    "                                            'low', \n",
    "                                            'close', \n",
    "                                            'volume'])\n",
    "\n",
    "X_valid_scaled = X_valid_scaled.drop(columns=['open', \n",
    "                                              'high', \n",
    "                                              'low', \n",
    "                                              'close', \n",
    "                                              'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a reward scheme encouraging rare volatile upside trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.env.default.rewards import TensorTradeRewardScheme\n",
    "\n",
    "\n",
    "class AnomalousProfit(TensorTradeRewardScheme):\n",
    "    \"\"\"A simple reward scheme that rewards the agent for exceeding a \n",
    "    precalculated percentage in the net worth.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float\n",
    "        The minimum value to exceed in order to get the reward.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    threshold : float\n",
    "        The minimum value to exceed in order to get the reward.\n",
    "    \"\"\"\n",
    "\n",
    "    registered_name = \"anomalous\"\n",
    "\n",
    "    def __init__(self, threshold: float = 0.02, window_size: int = 1):\n",
    "        self._window_size = self.default('window_size', window_size)\n",
    "        self._threshold = self.default('threshold', threshold)\n",
    "\n",
    "    def get_reward(self, portfolio: 'Portfolio') -> float:\n",
    "        \"\"\"Rewards the agent for incremental increases in net worth over a\n",
    "        sliding window.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        portfolio : `Portfolio`\n",
    "            The portfolio being used by the environment.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Whether the last percent change in net worth exceeds the predefined \n",
    "            `threshold`.\n",
    "        \"\"\"\n",
    "        performance = pd.DataFrame.from_dict(portfolio.performance).T\n",
    "        current_step = performance.shape[0]\n",
    "        if current_step > 1:\n",
    "            # Hint: make it cumulative.\n",
    "            net_worths = performance['net_worth']\n",
    "            ground_truths = precalculate_ground_truths(performance, \n",
    "                                                       column='net_worth', \n",
    "                                                       threshold=self._threshold)\n",
    "            reward_factor = 2.0 * ground_truths - 1.0\n",
    "            #return net_worths.iloc[-1] / net_worths.iloc[-min(current_step, self._window_size + 1)] - 1.0\n",
    "            return (reward_factor * net_worths.abs()).iloc[-1]\n",
    "\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PenalizedProfit(TensorTradeRewardScheme):\n",
    "    \"\"\"A reward scheme which penalizes net worth loss and \n",
    "    decays with the time spent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cash_penalty_proportion : float\n",
    "        cash_penalty_proportion\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cash_penalty_proportion : float\n",
    "        cash_penalty_proportion.\n",
    "    \"\"\"\n",
    "\n",
    "    registered_name = \"penalized\"\n",
    "\n",
    "    def __init__(self, cash_penalty_proportion: float = 0.10):\n",
    "        self._cash_penalty_proportion = \\\n",
    "            self.default('cash_penalty_proportion', \n",
    "                         cash_penalty_proportion)\n",
    "\n",
    "    def get_reward(self, portfolio: 'Portfolio') -> float:\n",
    "        \"\"\"Rewards the agent for gaining net worth while holding the asset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        portfolio : `Portfolio`\n",
    "            The portfolio being used by the environment.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            A penalized reward.\n",
    "        \"\"\"\n",
    "        performance = pd.DataFrame.from_dict(portfolio.performance).T\n",
    "        current_step = performance.shape[0]\n",
    "        if current_step > 1:\n",
    "            initial_amount = portfolio.initial_net_worth\n",
    "            asset_worth = performance['bitstamp:/BTC:/worth'].iloc[-1]\n",
    "            cash_worth = performance['bitstamp:/USD:/total'].iloc[-1]\n",
    "            cash_penalty = max(0, (asset_worth * self._cash_penalty_proportion - cash_worth))\n",
    "            asset_worth -= cash_penalty\n",
    "            reward = (asset_worth / initial_amount) - 1\n",
    "            reward /= current_step\n",
    "            return reward\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: implement tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensortrade.env.default as default\n",
    "\n",
    "#from tensortrade.agents import DQNAgent\n",
    "from tensortrade.feed.core import DataFeed, Stream\n",
    "from tensortrade.feed.core.base import NameSpace\n",
    "from tensortrade.env.default.actions import BSH, ManagedRiskOrders\n",
    "from tensortrade.env.default.rewards import RiskAdjustedReturns, SimpleProfit\n",
    "from tensortrade.oms.exchanges import Exchange, ExchangeOptions\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.oms.instruments import USD, BTC, ETH\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "from tensortrade.oms.orders import TradeType\n",
    "\n",
    "# TODO: adjust according to your commission percentage, if present\n",
    "commission = 0.001\n",
    "price = Stream.source(list(X_train[\"close\"]), \n",
    "                      dtype=\"float\").rename(\"USD-BTC\")\n",
    "bitstamp_options = ExchangeOptions(commission=commission)\n",
    "bitstamp = Exchange(\"bitstamp\", \n",
    "                    service=execute_order, \n",
    "                    options=bitstamp_options)(price)\n",
    "\n",
    "cash = Wallet(bitstamp, 50000 * USD)\n",
    "asset = Wallet(bitstamp, 0 * BTC)\n",
    "\n",
    "portfolio = Portfolio(USD, [cash, asset])\n",
    "\n",
    "with NameSpace(\"bitstamp\"):\n",
    "    features = [\n",
    "        Stream.source(list(X_train_scaled[c]), \n",
    "                      dtype=\"float\").rename(c) for c in X_train_scaled.columns[1:]\n",
    "        #Stream.source(list(X_train_scaled['lr_close']), dtype=\"float\").rename('lr_close')\n",
    "    ]\n",
    "\n",
    "feed = DataFeed(features)\n",
    "feed.compile()\n",
    "\n",
    "renderer_feed = DataFeed([\n",
    "    Stream.source(list(X_train[\"date\"])).rename(\"date\"),\n",
    "    Stream.source(list(X_train[\"open\"]), dtype=\"float\").rename(\"open\"),\n",
    "    Stream.source(list(X_train[\"high\"]), dtype=\"float\").rename(\"high\"),\n",
    "    Stream.source(list(X_train[\"low\"]), dtype=\"float\").rename(\"low\"),\n",
    "    Stream.source(list(X_train[\"close\"]), dtype=\"float\").rename(\"close\"), \n",
    "    Stream.source(list(X_train[\"volume\"]), dtype=\"float\").rename(\"volume\") \n",
    "])\n",
    "\n",
    "action_scheme = BSH(\n",
    "    cash=cash,\n",
    "    asset=asset\n",
    ")\n",
    "\n",
    "#reward_scheme = RiskAdjustedReturns(return_algorithm='sortino',\n",
    "#                                    window_size=30)\n",
    "\n",
    "#reward_scheme = SimpleProfit(window_size=30)\n",
    "\n",
    "#reward_scheme = AnomalousProfit(threshold=threshold)\n",
    "\n",
    "reward_scheme = PenalizedProfit(cash_penalty_proportion=0.1)\n",
    "\n",
    "env = default.create(\n",
    "    portfolio=portfolio,\n",
    "    action_scheme=action_scheme,\n",
    "    reward_scheme=reward_scheme,\n",
    "    feed=feed,\n",
    "    renderer_feed=renderer_feed,\n",
    "    renderer=default.renderers.PlotlyTradingChart(),\n",
    "    window_size=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /usr/local/lib/python3.8/dist-packages/tensortrade/agents/a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.agents.a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observer.feed.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Train DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_batch_size(window_size=30, n_steps=1000, batch_factor=4, stride=1):\n",
    "    \"\"\"\n",
    "    lookback = 30          # Days of past data (also named window_size).\n",
    "    batch_factor = 4       # batch_size = (sample_size - lookback - stride) // batch_factor\n",
    "    stride = 1             # Time series shift into the future.\n",
    "    \"\"\"\n",
    "    lookback = window_size\n",
    "    sample_size = n_steps\n",
    "    batch_size = ((sample_size - lookback - stride) // batch_factor)\n",
    "    return batch_size\n",
    "\n",
    "batch_size = get_optimal_batch_size(window_size=window_size, n_steps=n_steps, batch_factor=4)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#agent = DQNAgent(env)\n",
    "#\n",
    "#agent.train(batch_size=batch_size, \n",
    "#            n_steps=n_steps, \n",
    "#            n_episodes=n_episodes, \n",
    "#            memory_capacity=memory_capacity, \n",
    "#            save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement validation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print basic quantstats report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quantstats_full_report(env, data, output='dqn_quantstats'):\n",
    "    performance = pd.DataFrame.from_dict(env.action_scheme.portfolio.performance, orient='index')\n",
    "    net_worth = performance['net_worth'].iloc[window_size:]\n",
    "    returns = net_worth.pct_change().iloc[1:]\n",
    "\n",
    "    # WARNING! The dates are fake and default parameters are used!\n",
    "    returns.index = pd.date_range(start=data['date'].iloc[0], freq='1d', periods=returns.size)\n",
    "\n",
    "    qs.reports.full(returns)\n",
    "    qs.reports.html(returns, output=output + '.html')\n",
    "\n",
    "#print_quantstats_full_report(env, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_allowed_loss = 0.90\n",
    "min_periods = window_size  # Minimum of window_size\n",
    "\n",
    "observer = default.observers.TensorTradeObserver(\n",
    "    portfolio=portfolio,\n",
    "    feed=feed,\n",
    "    renderer_feed=renderer_feed,\n",
    "    window_size=window_size,\n",
    "    min_periods=min_periods\n",
    ")\n",
    "\n",
    "stopper = default.stoppers.MaxLossStopper(\n",
    "    max_allowed_loss=max_allowed_loss\n",
    ")\n",
    "\n",
    "informer = default.informers.TensorTradeInformer()\n",
    "\n",
    "renderer = default.renderers.PlotlyTradingChart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt update\n",
    "#!apt install -y swig cmake libz-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.agents.txt\n",
    "#!yes | pip uninstall opencv-python\n",
    "#!pip install opencv-python\n",
    "#!pip install --upgrade gym==0.21.0 gym-wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.envs.register(\n",
    "    id='TradingEnv-v0',\n",
    "    entry_point='tensortrade.env.generic.environment:TradingEnv',\n",
    "    kwargs={\n",
    "        'portfolio': portfolio,\n",
    "        'action_scheme': action_scheme,\n",
    "        'reward_scheme': reward_scheme,\n",
    "        'observer': observer,\n",
    "        'stopper': stopper,\n",
    "        'informer': informer,\n",
    "        'feed': feed,\n",
    "        'renderer_feed': renderer_feed,\n",
    "        'renderer': renderer,\n",
    "        'min_periods': min_periods,\n",
    "        'window_size': window_size,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensortrade.agents as agents\n",
    "from tensortrade.agents import DQN\n",
    "from tensortrade.agents.utils.common import ModelReader, create_envs\n",
    "\n",
    "envs = create_envs('TradingEnv-v0', preprocess=False, model='models/')\n",
    "model = ModelReader(\n",
    "    tensortrade.agents.agents['dqn']['model']['cnn'][0],\n",
    "    output_units=[1],\n",
    "    input_shape=envs[0].observation_space.shape,\n",
    "    optimizer='adam',\n",
    ").build_model()\n",
    "\n",
    "model.load_weights(\n",
    "    'agents/trained-weights.tf'\n",
    ").expect_partial()\n",
    "\n",
    "agent = A2C(envs, model)\n",
    "agent.play(render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
