{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zf8ju5mw4f",
   "source": "# Attention Network Training with Ray RLlib\n\nThis notebook demonstrates training a PPO agent with Transformer/Attention architecture using Ray RLlib.\n\n## ðŸ“š Related Tutorials\n\n| Tutorial | Description |\n|----------|-------------|\n| [Ray RLlib Deep Dive](../docs/tutorials/04-training/02-ray-rllib.md) | Distributed training configuration |\n| [Optuna Optimization](../docs/tutorials/04-training/03-optuna.md) | Hyperparameter tuning guide |\n| [First Training](../docs/tutorials/04-training/01-first-training.md) | Training fundamentals |\n| [Common Failures](../docs/tutorials/02-domains/track-b-rl-for-traders/02-common-failures.md) | **Critical pitfalls to avoid** |\n| [Overfitting](../docs/tutorials/05-advanced/01-overfitting.md) | Detection and prevention |\n\n### ðŸ” Attention vs LSTM\n\nAttention networks can capture long-range dependencies better than LSTMs for some trading patterns. However, they require more memory and compute. Start with LSTM (see `use_lstm_rllib.ipynb`) before experimenting with attention.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b56ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf /root/ray_results/ /root/ray_results/PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8221f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.data.cdd import CryptoDataDownload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['volume'] = np.int64(df['volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d %I:%M %p')\n",
    "    return df\n",
    "\n",
    "def fetch_data():\n",
    "    cdd = CryptoDataDownload()\n",
    "    bitfinex_data = cdd.fetch(\"Bitfinex\", \"USD\", \"BTC\", \"1h\")\n",
    "    bitfinex_data = bitfinex_data[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    bitfinex_data = prepare_data(bitfinex_data)\n",
    "    return bitfinex_data\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv('data/' + filename, skiprows=1)\n",
    "    df.drop(columns=['symbol', 'volume_btc'], inplace=True)\n",
    "\n",
    "    # Fix timestamp form \"2019-10-17 09-AM\" to \"2019-10-17 09-00-00 AM\"\n",
    "    df['date'] = df['date'].str[:14] + '00-00 ' + df['date'].str[-2:]\n",
    "\n",
    "    return prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6071b91",
   "metadata": {},
   "outputs": [],
   "source": "import ta\n\ndef rsi(price: 'pd.Series[pd.Float64Dtype]', period: float) -> 'pd.Series[pd.Float64Dtype]':\n    r = price.diff()\n    upside = np.minimum(r, 0).abs()\n    downside = np.maximum(r, 0).abs()\n    rs = upside.ewm(alpha=1 / period).mean() / downside.ewm(alpha=1 / period).mean()\n    return 100*(1 - (1 + rs) ** -1)\n\ndef macd(price: 'pd.Series[pd.Float64Dtype]', fast: float, slow: float, signal: float) -> 'pd.Series[pd.Float64Dtype]':\n    fm = price.ewm(span=fast, adjust=False).mean()\n    sm = price.ewm(span=slow, adjust=False).mean()\n    md = fm - sm\n    signal = md - md.ewm(span=signal, adjust=False).mean()\n    return signal\n\ndef generate_features(data):\n    # Naming convention across most technical indicator libraries\n    data = data.rename(columns={'date': 'Date', \n                                'open': 'Open', \n                                'high': 'High', \n                                'low': 'Low', \n                                'close': 'Close', \n                                'volume': 'Volume'})\n    data = data.set_index('Date')\n\n    # Custom indicators\n    features = pd.DataFrame.from_dict({\n        'dfast': data['Close'].rolling(window=10).std().abs(),\n        'dmedium': data['Close'].rolling(window=50).std().abs(),\n        'dslow': data['Close'].rolling(window=100).std().abs(),\n        'fast': data['Close'].rolling(window=10).mean(),\n        'medium': data['Close'].rolling(window=50).mean(),\n        'slow': data['Close'].rolling(window=100).mean(),\n        'ema_fast': ta.trend.ema_indicator(data['Close'], window=5, fillna=True),\n        'ema_medium': ta.trend.ema_indicator(data['Close'], window=10, fillna=True),\n        'ema_slow': ta.trend.ema_indicator(data['Close'], window=64, fillna=True),\n        'lr': np.log(data['Close']).diff().fillna(0),\n        'rsi_5': rsi(data['Close'], period=5),\n        'rsi_10': rsi(data['Close'], period=10),\n        'rsi_100': rsi(data['Close'], period=100),\n        'rsi_7': rsi(data['Close'], period=7),\n        'rsi_14': rsi(data['Close'], period=14),\n        'rsi_28': rsi(data['Close'], period=28),\n        'macd_normal': macd(data['Close'], fast=12, slow=26, signal=9),\n        'macd_short': macd(data['Close'], fast=10, slow=50, signal=5),\n        'macd_long': macd(data['Close'], fast=200, slow=100, signal=50),\n    })\n\n    # Generate all default indicators from ta library\n    ta.add_all_ta_features(data, \n                           'Open', \n                           'High', \n                           'Low', \n                           'Close', \n                           'Volume', \n                           fillna=True)\n\n    # Concatenate both manually and automatically generated features\n    data = pd.concat([data, features], axis='columns').ffill()\n\n    # Remove potential column duplicates\n    data = data.loc[:,~data.columns.duplicated()]\n\n    # Revert naming convention\n    data = data.rename(columns={'Date': 'date', \n                                'Open': 'open', \n                                'High': 'high', \n                                'Low': 'low', \n                                'Close': 'close', \n                                'Volume': 'volume'})\n\n    # A lot of indicators generate NaNs at the beginning of DataFrames, so remove them\n    data = data.iloc[200:]\n    data = data.reset_index(drop=True)\n\n    return data"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e748bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.copy()\n",
    "    y = X['close'].pct_change()\n",
    "\n",
    "    X_train_test, X_valid, y_train_test, y_valid = \\\n",
    "        train_test_split(data, data['close'].pct_change(), train_size=0.67, test_size=0.33, shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_train_test, y_train_test, train_size=0.50, test_size=0.50, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8fcc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-15 06:00 AM</td>\n",
       "      <td>8723.8</td>\n",
       "      <td>8793.0</td>\n",
       "      <td>8714.9</td>\n",
       "      <td>8739.0</td>\n",
       "      <td>8988053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-15 07:00 AM</td>\n",
       "      <td>8739.0</td>\n",
       "      <td>8754.8</td>\n",
       "      <td>8719.3</td>\n",
       "      <td>8743.0</td>\n",
       "      <td>2288904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-15 08:00 AM</td>\n",
       "      <td>8743.0</td>\n",
       "      <td>8743.1</td>\n",
       "      <td>8653.2</td>\n",
       "      <td>8723.7</td>\n",
       "      <td>8891773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-15 09:00 AM</td>\n",
       "      <td>8723.7</td>\n",
       "      <td>8737.8</td>\n",
       "      <td>8701.2</td>\n",
       "      <td>8708.1</td>\n",
       "      <td>2054868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15 10:00 AM</td>\n",
       "      <td>8708.1</td>\n",
       "      <td>8855.7</td>\n",
       "      <td>8695.8</td>\n",
       "      <td>8784.4</td>\n",
       "      <td>17309722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65042</th>\n",
       "      <td>2025-10-15 09:00 PM</td>\n",
       "      <td>111320.0</td>\n",
       "      <td>111500.0</td>\n",
       "      <td>110710.0</td>\n",
       "      <td>110960.0</td>\n",
       "      <td>5257176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043</th>\n",
       "      <td>2025-10-15 10:00 PM</td>\n",
       "      <td>110970.0</td>\n",
       "      <td>111500.0</td>\n",
       "      <td>110830.0</td>\n",
       "      <td>110830.0</td>\n",
       "      <td>3081976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65044</th>\n",
       "      <td>2025-10-15 11:00 PM</td>\n",
       "      <td>110820.0</td>\n",
       "      <td>111180.0</td>\n",
       "      <td>110770.0</td>\n",
       "      <td>110920.0</td>\n",
       "      <td>3135737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65045</th>\n",
       "      <td>2025-10-16 12:00 AM</td>\n",
       "      <td>110950.0</td>\n",
       "      <td>111010.0</td>\n",
       "      <td>110540.0</td>\n",
       "      <td>110660.0</td>\n",
       "      <td>5250807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65046</th>\n",
       "      <td>2025-10-16 01:00 AM</td>\n",
       "      <td>110650.0</td>\n",
       "      <td>111200.0</td>\n",
       "      <td>110610.0</td>\n",
       "      <td>111200.0</td>\n",
       "      <td>629765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65047 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date      open      high       low     close    volume\n",
       "0      2018-05-15 06:00 AM    8723.8    8793.0    8714.9    8739.0   8988053\n",
       "1      2018-05-15 07:00 AM    8739.0    8754.8    8719.3    8743.0   2288904\n",
       "2      2018-05-15 08:00 AM    8743.0    8743.1    8653.2    8723.7   8891773\n",
       "3      2018-05-15 09:00 AM    8723.7    8737.8    8701.2    8708.1   2054868\n",
       "4      2018-05-15 10:00 AM    8708.1    8855.7    8695.8    8784.4  17309722\n",
       "...                    ...       ...       ...       ...       ...       ...\n",
       "65042  2025-10-15 09:00 PM  111320.0  111500.0  110710.0  110960.0   5257176\n",
       "65043  2025-10-15 10:00 PM  110970.0  111500.0  110830.0  110830.0   3081976\n",
       "65044  2025-10-15 11:00 PM  110820.0  111180.0  110770.0  110920.0   3135737\n",
       "65045  2025-10-16 12:00 AM  110950.0  111010.0  110540.0  110660.0   5250807\n",
       "65046  2025-10-16 01:00 AM  110650.0  111200.0  110610.0  111200.0    629765\n",
       "\n",
       "[65047 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1cf7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n",
      "/tmp/ipykernel_19/119484119.py:60: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = pd.concat([data, features], axis='columns').fillna(method='pad')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>...</th>\n",
       "      <th>lr</th>\n",
       "      <th>rsi_5</th>\n",
       "      <th>rsi_10</th>\n",
       "      <th>rsi_100</th>\n",
       "      <th>rsi_7</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>rsi_28</th>\n",
       "      <th>macd_normal</th>\n",
       "      <th>macd_short</th>\n",
       "      <th>macd_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7897.3</td>\n",
       "      <td>7898.8</td>\n",
       "      <td>7849.8</td>\n",
       "      <td>7877.4</td>\n",
       "      <td>9341499</td>\n",
       "      <td>-1.219515e+08</td>\n",
       "      <td>-153103304</td>\n",
       "      <td>-0.175983</td>\n",
       "      <td>-1.548039e+08</td>\n",
       "      <td>-1.586737e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002523</td>\n",
       "      <td>54.694594</td>\n",
       "      <td>62.862413</td>\n",
       "      <td>58.177953</td>\n",
       "      <td>58.867381</td>\n",
       "      <td>65.249906</td>\n",
       "      <td>64.898857</td>\n",
       "      <td>11.190548</td>\n",
       "      <td>10.871904</td>\n",
       "      <td>31.873058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7877.4</td>\n",
       "      <td>7889.7</td>\n",
       "      <td>7661.0</td>\n",
       "      <td>7700.0</td>\n",
       "      <td>23679375</td>\n",
       "      <td>-1.375548e+08</td>\n",
       "      <td>-176782679</td>\n",
       "      <td>-0.228723</td>\n",
       "      <td>-7.327921e+08</td>\n",
       "      <td>-9.556783e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022778</td>\n",
       "      <td>83.970505</td>\n",
       "      <td>78.146122</td>\n",
       "      <td>60.860099</td>\n",
       "      <td>80.595405</td>\n",
       "      <td>76.335665</td>\n",
       "      <td>71.316639</td>\n",
       "      <td>1.333779</td>\n",
       "      <td>-5.426751</td>\n",
       "      <td>34.355233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7700.0</td>\n",
       "      <td>7700.1</td>\n",
       "      <td>7548.1</td>\n",
       "      <td>7605.4</td>\n",
       "      <td>42144843</td>\n",
       "      <td>-1.479246e+08</td>\n",
       "      <td>-218927522</td>\n",
       "      <td>-0.216859</td>\n",
       "      <td>-1.197665e+09</td>\n",
       "      <td>-5.454997e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012362</td>\n",
       "      <td>88.796304</td>\n",
       "      <td>82.430355</td>\n",
       "      <td>62.167022</td>\n",
       "      <td>85.395126</td>\n",
       "      <td>79.999761</td>\n",
       "      <td>73.950511</td>\n",
       "      <td>-10.060459</td>\n",
       "      <td>-21.497215</td>\n",
       "      <td>37.504922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7605.4</td>\n",
       "      <td>7623.6</td>\n",
       "      <td>7441.8</td>\n",
       "      <td>7511.1</td>\n",
       "      <td>38711817</td>\n",
       "      <td>-1.571235e+08</td>\n",
       "      <td>-257639339</td>\n",
       "      <td>-0.221424</td>\n",
       "      <td>-1.548073e+09</td>\n",
       "      <td>-4.292364e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012477</td>\n",
       "      <td>91.852619</td>\n",
       "      <td>85.564709</td>\n",
       "      <td>63.397644</td>\n",
       "      <td>88.657814</td>\n",
       "      <td>82.850341</td>\n",
       "      <td>76.208878</td>\n",
       "      <td>-21.778972</td>\n",
       "      <td>-36.146245</td>\n",
       "      <td>41.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7511.1</td>\n",
       "      <td>7551.6</td>\n",
       "      <td>7403.0</td>\n",
       "      <td>7489.1</td>\n",
       "      <td>23046091</td>\n",
       "      <td>-1.534634e+08</td>\n",
       "      <td>-280685430</td>\n",
       "      <td>-0.149460</td>\n",
       "      <td>-1.399351e+09</td>\n",
       "      <td>-3.572163e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002933</td>\n",
       "      <td>92.453006</td>\n",
       "      <td>86.202747</td>\n",
       "      <td>63.676078</td>\n",
       "      <td>89.307939</td>\n",
       "      <td>83.443225</td>\n",
       "      <td>76.697643</td>\n",
       "      <td>-28.422775</td>\n",
       "      <td>-41.976877</td>\n",
       "      <td>44.917996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64842</th>\n",
       "      <td>111320.0</td>\n",
       "      <td>111500.0</td>\n",
       "      <td>110710.0</td>\n",
       "      <td>110960.0</td>\n",
       "      <td>5257176</td>\n",
       "      <td>1.114645e+10</td>\n",
       "      <td>-6857940235</td>\n",
       "      <td>-0.124668</td>\n",
       "      <td>-7.943209e+08</td>\n",
       "      <td>-2.554603e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003329</td>\n",
       "      <td>72.687665</td>\n",
       "      <td>67.626207</td>\n",
       "      <td>55.828693</td>\n",
       "      <td>70.377509</td>\n",
       "      <td>64.815877</td>\n",
       "      <td>59.746825</td>\n",
       "      <td>-65.579183</td>\n",
       "      <td>-54.857915</td>\n",
       "      <td>112.449141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64843</th>\n",
       "      <td>110970.0</td>\n",
       "      <td>111500.0</td>\n",
       "      <td>110830.0</td>\n",
       "      <td>110830.0</td>\n",
       "      <td>3081976</td>\n",
       "      <td>1.114337e+10</td>\n",
       "      <td>-6861022211</td>\n",
       "      <td>-0.136256</td>\n",
       "      <td>-7.380831e+08</td>\n",
       "      <td>1.304358e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>75.660705</td>\n",
       "      <td>69.234848</td>\n",
       "      <td>55.980510</td>\n",
       "      <td>72.591532</td>\n",
       "      <td>65.989853</td>\n",
       "      <td>60.328089</td>\n",
       "      <td>-71.870601</td>\n",
       "      <td>-70.237035</td>\n",
       "      <td>117.961020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64844</th>\n",
       "      <td>110820.0</td>\n",
       "      <td>111180.0</td>\n",
       "      <td>110770.0</td>\n",
       "      <td>110920.0</td>\n",
       "      <td>3135737</td>\n",
       "      <td>1.114253e+10</td>\n",
       "      <td>-6857886474</td>\n",
       "      <td>-0.117275</td>\n",
       "      <td>-5.923261e+08</td>\n",
       "      <td>-2.484264e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>69.147050</td>\n",
       "      <td>66.685926</td>\n",
       "      <td>55.846283</td>\n",
       "      <td>68.458812</td>\n",
       "      <td>64.388077</td>\n",
       "      <td>59.709066</td>\n",
       "      <td>-62.414190</td>\n",
       "      <td>-59.247345</td>\n",
       "      <td>121.781193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64845</th>\n",
       "      <td>110950.0</td>\n",
       "      <td>111010.0</td>\n",
       "      <td>110540.0</td>\n",
       "      <td>110660.0</td>\n",
       "      <td>5250807</td>\n",
       "      <td>1.113996e+10</td>\n",
       "      <td>-6863137281</td>\n",
       "      <td>-0.158900</td>\n",
       "      <td>-7.027380e+08</td>\n",
       "      <td>-1.790201e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002347</td>\n",
       "      <td>76.463972</td>\n",
       "      <td>70.206705</td>\n",
       "      <td>56.153071</td>\n",
       "      <td>73.536588</td>\n",
       "      <td>66.888530</td>\n",
       "      <td>60.910694</td>\n",
       "      <td>-65.776993</td>\n",
       "      <td>-68.407626</td>\n",
       "      <td>127.330833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64846</th>\n",
       "      <td>110650.0</td>\n",
       "      <td>111200.0</td>\n",
       "      <td>110610.0</td>\n",
       "      <td>111200.0</td>\n",
       "      <td>629765</td>\n",
       "      <td>1.114059e+10</td>\n",
       "      <td>-6862507516</td>\n",
       "      <td>-0.156126</td>\n",
       "      <td>-5.537650e+08</td>\n",
       "      <td>1.217915e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>47.325892</td>\n",
       "      <td>56.441379</td>\n",
       "      <td>55.346309</td>\n",
       "      <td>52.900668</td>\n",
       "      <td>57.809717</td>\n",
       "      <td>57.234206</td>\n",
       "      <td>-25.794298</td>\n",
       "      <td>-11.213853</td>\n",
       "      <td>126.912231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64847 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open      high       low     close    volume    volume_adi  \\\n",
       "0        7897.3    7898.8    7849.8    7877.4   9341499 -1.219515e+08   \n",
       "1        7877.4    7889.7    7661.0    7700.0  23679375 -1.375548e+08   \n",
       "2        7700.0    7700.1    7548.1    7605.4  42144843 -1.479246e+08   \n",
       "3        7605.4    7623.6    7441.8    7511.1  38711817 -1.571235e+08   \n",
       "4        7511.1    7551.6    7403.0    7489.1  23046091 -1.534634e+08   \n",
       "...         ...       ...       ...       ...       ...           ...   \n",
       "64842  111320.0  111500.0  110710.0  110960.0   5257176  1.114645e+10   \n",
       "64843  110970.0  111500.0  110830.0  110830.0   3081976  1.114337e+10   \n",
       "64844  110820.0  111180.0  110770.0  110920.0   3135737  1.114253e+10   \n",
       "64845  110950.0  111010.0  110540.0  110660.0   5250807  1.113996e+10   \n",
       "64846  110650.0  111200.0  110610.0  111200.0    629765  1.114059e+10   \n",
       "\n",
       "       volume_obv  volume_cmf     volume_fi     volume_em  ...        lr  \\\n",
       "0      -153103304   -0.175983 -1.548039e+08 -1.586737e+04  ... -0.002523   \n",
       "1      -176782679   -0.228723 -7.327921e+08 -9.556783e+04  ... -0.022778   \n",
       "2      -218927522   -0.216859 -1.197665e+09 -5.454997e+04  ... -0.012362   \n",
       "3      -257639339   -0.221424 -1.548073e+09 -4.292364e+04  ... -0.012477   \n",
       "4      -280685430   -0.149460 -1.399351e+09 -3.572163e+04  ... -0.002933   \n",
       "...           ...         ...           ...           ...  ...       ...   \n",
       "64842 -6857940235   -0.124668 -7.943209e+08 -2.554603e+06  ... -0.003329   \n",
       "64843 -6861022211   -0.136256 -7.380831e+08  1.304358e+06  ... -0.001172   \n",
       "64844 -6857886474   -0.117275 -5.923261e+08 -2.484264e+06  ...  0.000812   \n",
       "64845 -6863137281   -0.158900 -7.027380e+08 -1.790201e+06  ... -0.002347   \n",
       "64846 -6862507516   -0.156126 -5.537650e+08  1.217915e+07  ...  0.004868   \n",
       "\n",
       "           rsi_5     rsi_10    rsi_100      rsi_7     rsi_14     rsi_28  \\\n",
       "0      54.694594  62.862413  58.177953  58.867381  65.249906  64.898857   \n",
       "1      83.970505  78.146122  60.860099  80.595405  76.335665  71.316639   \n",
       "2      88.796304  82.430355  62.167022  85.395126  79.999761  73.950511   \n",
       "3      91.852619  85.564709  63.397644  88.657814  82.850341  76.208878   \n",
       "4      92.453006  86.202747  63.676078  89.307939  83.443225  76.697643   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "64842  72.687665  67.626207  55.828693  70.377509  64.815877  59.746825   \n",
       "64843  75.660705  69.234848  55.980510  72.591532  65.989853  60.328089   \n",
       "64844  69.147050  66.685926  55.846283  68.458812  64.388077  59.709066   \n",
       "64845  76.463972  70.206705  56.153071  73.536588  66.888530  60.910694   \n",
       "64846  47.325892  56.441379  55.346309  52.900668  57.809717  57.234206   \n",
       "\n",
       "       macd_normal  macd_short   macd_long  \n",
       "0        11.190548   10.871904   31.873058  \n",
       "1         1.333779   -5.426751   34.355233  \n",
       "2       -10.060459  -21.497215   37.504922  \n",
       "3       -21.778972  -36.146245   41.269618  \n",
       "4       -28.422775  -41.976877   44.917996  \n",
       "...            ...         ...         ...  \n",
       "64842   -65.579183  -54.857915  112.449141  \n",
       "64843   -71.870601  -70.237035  117.961020  \n",
       "64844   -62.414190  -59.247345  121.781193  \n",
       "64845   -65.776993  -68.407626  127.330833  \n",
       "64846   -25.794298  -11.213853  126.912231  \n",
       "\n",
       "[64847 rows x 110 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = generate_features(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855ee4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = \\\n",
    "    split_data(data)\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "train_csv = os.path.join(cwd, 'train.csv')\n",
    "test_csv = os.path.join(cwd, 'test.csv')\n",
    "valid_csv = os.path.join(cwd, 'valid.csv')\n",
    "X_train.to_csv(train_csv, index=False)\n",
    "X_test.to_csv(test_csv, index=False)\n",
    "X_valid.to_csv(valid_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705bd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to understand here:\n",
    "# Writing a Renderer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensortrade.env.generic import Renderer\n",
    "\n",
    "\n",
    "class PositionChangeChart(Renderer):\n",
    "    def __init__(self, color: str = \"orange\"):\n",
    "        self.color = \"orange\"\n",
    "\n",
    "    def render(self, env, **kwargs):\n",
    "        history = pd.DataFrame(env.observer.renderer_history)\n",
    "\n",
    "        actions = list(history.action)\n",
    "        price = list(history.close)\n",
    "\n",
    "        buy = {}\n",
    "        sell = {}\n",
    "\n",
    "        for i in range(len(actions) - 1):\n",
    "            a1 = actions[i]\n",
    "            a2 = actions[i + 1]\n",
    "\n",
    "            if a1 != a2:\n",
    "                if a1 == 0 and a2 == 1:\n",
    "                    buy[i] = price[i]\n",
    "                else:\n",
    "                    sell[i] = price[i]\n",
    "\n",
    "        buy = pd.Series(buy)\n",
    "        sell = pd.Series(sell)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        fig.suptitle(\"Performance\")\n",
    "\n",
    "        axs[0].plot(np.arange(len(price)), price, label=\"price\", color=self.color)\n",
    "        axs[0].scatter(buy.index, buy.values, marker=\"^\", color=\"green\")\n",
    "        axs[0].scatter(sell.index, sell.values, marker=\"^\", color=\"red\")\n",
    "        axs[0].set_title(\"Trading Chart\")\n",
    "\n",
    "        performance_df = pd.DataFrame().from_dict(env.action_scheme.portfolio.performance, orient='index')\n",
    "        performance_df.plot(ax=axs[1])\n",
    "        axs[1].set_title(\"Net Worth\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7f27d",
   "metadata": {},
   "outputs": [],
   "source": "# Things to understand here:\n# execution_order\n# Types of execution logic\n# Exchange\n# DataFeed\n# renderer_feed\n# default (env)\n\nimport ray\nimport numpy as np\nimport pandas as pd\n\nfrom ray import tune\nfrom ray.tune.registry import register_env\n\nimport tensortrade.env.default as default\n\nfrom tensortrade.env.default.rewards import PBR, RiskAdjustedReturns\nfrom tensortrade.env.default.rewards import SimpleProfit\nfrom tensortrade.env.default.actions import BSH, ManagedRiskOrders\nfrom tensortrade.feed.core import DataFeed, Stream\nfrom tensortrade.feed.core.base import NameSpace\nfrom tensortrade.oms.exchanges import Exchange, ExchangeOptions\nfrom tensortrade.oms.instruments import USD, BTC\nfrom tensortrade.oms.services.execution.simulated import execute_order\nfrom tensortrade.oms.wallets import Wallet, Portfolio\n\ndef create_env(config):\n    data = pd.read_csv(filepath_or_buffer=config[\"csv_filename\"], \n                       parse_dates=['date']).bfill().ffill()\n\n    # TODO: adjust according to your commission percentage, if present\n    commission = 0.01\n    price = Stream.source(list(data[\"close\"]), \n                          dtype=\"float\").rename(\"USD-BTC\")\n    bitstamp_options = ExchangeOptions(commission=commission)\n    bitstamp = Exchange(\"bitstamp\", \n                        service=execute_order, \n                        options=bitstamp_options)(price)\n\n    cash = Wallet(bitstamp, 10000 * USD)\n    asset = Wallet(bitstamp, 0 * BTC)\n\n    portfolio = Portfolio(USD, [cash, asset])\n\n    '''\n    # Custom indicators\n    features = pd.DataFrame.from_dict({\n        'dfast': data['close'].rolling(window=10).std().abs(),\n        'dmedium': data['close'].rolling(window=50).std().abs(),\n        'dslow': data['close'].rolling(window=100).std().abs(),\n        'fast': data['close'].rolling(window=10).mean(),\n        'medium': data['close'].rolling(window=50).mean(),\n        'slow': data['close'].rolling(window=100).mean(),\n        'ema_fast': ta.trend.ema_indicator(data['close'], window=5, fillna=True),\n        'ema_medium': ta.trend.ema_indicator(data['close'], window=10, fillna=True),\n        'ema_slow': ta.trend.ema_indicator(data['close'], window=64, fillna=True),\n        'lr': np.log(data['close']).diff().fillna(0),\n        'rsi_5': rsi(data['close'], period=5),\n        'rsi_10': rsi(data['close'], period=10),\n        'rsi_100': rsi(data['close'], period=100),\n        'rsi_7': rsi(data['close'], period=7),\n        'rsi_14': rsi(data['close'], period=14),\n        'rsi_28': rsi(data['close'], period=28),\n        'macd_normal': macd(data['close'], fast=12, slow=26, signal=9),\n        'macd_short': macd(data['close'], fast=10, slow=50, signal=5),\n        'macd_long': macd(data['close'], fast=200, slow=100, signal=50),\n    })\n\n    ta.add_all_ta_features(data, \n                           'open', \n                           'high', \n                           'low', \n                           'close', \n                           'volume', \n                           fillna=True)\n    '''\n\n    with NameSpace(\"bitstamp\"):\n        #data = pd.concat([data, features], axis='columns')\n        automatic_features = [\n            Stream.source(list(data[c]), \n                          dtype=\"float\").rename(c) for c in data.columns[1:]\n        ]\n\n    feed = DataFeed(automatic_features)\n    feed.compile()\n\n    reward_scheme = PBR(price=price)\n\n    action_scheme = BSH(\n        cash=cash,\n        asset=asset\n    ).attach(reward_scheme)\n\n    renderer_feed = DataFeed([\n        Stream.source(list(data[\"date\"])).rename(\"date\"),\n        Stream.source(list(data[\"open\"]), dtype=\"float\").rename(\"open\"),\n        Stream.source(list(data[\"high\"]), dtype=\"float\").rename(\"high\"),\n        Stream.source(list(data[\"low\"]), dtype=\"float\").rename(\"low\"),\n        Stream.source(list(data[\"close\"]), dtype=\"float\").rename(\"close\"), \n        Stream.source(list(data[\"volume\"]), dtype=\"float\").rename(\"volume\"), \n        Stream.sensor(action_scheme, \n                      lambda s: s.action, dtype=\"float\").rename(\"action\")\n    ])\n\n    environment = default.create(\n        feed=feed,\n        portfolio=portfolio,\n        action_scheme=action_scheme,\n        reward_scheme=reward_scheme,\n        renderer_feed=renderer_feed,\n        renderer=[\n            PositionChangeChart(),\n            default.renderers.PlotlyTradingChart(),\n        ],\n        window_size=config[\"window_size\"],\n        max_allowed_loss=0.9\n    )\n    return environment\n\nray.init(num_cpus=3,\n         include_dashboard=True,\n         address=None,  # set `address=None` to train on laptop\n         ignore_reinit_error=True)\n\nregister_env(\"TradingEnv\", create_env)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082cb70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "from ray.tune.schedulers import ASHAScheduler\nfrom ray.tune.search import ConcurrencyLimiter\nfrom ray.tune.search.optuna import OptunaSearch\nfrom ray.tune import TuneConfig, RunConfig\nfrom ray.train import CheckpointConfig\n\nLR = tune.loguniform(1e-5, 1e-2)\nGAMMA = tune.uniform(0.8, 0.9999)\nLAMBDA = tune.uniform(0.1, 0.8)\nVF_LOSS_COEFF = tune.uniform(0.01, 1.0)\nENTROPY_COEFF = tune.uniform(1e-8, 1e-1)\n\ncheckpoint_metric = 'env_runners/episode_reward_mean'\n\n# Specific configuration keys that will be used during training\nenv_config_training = {\n    \"window_size\": 14,  # The number of past samples we want to look at (in hours)\n    \"reward_window_size\": 7,  # The number of hours we want to look at in the future to calculate the rewards based on the actions taken\n    \"max_allowed_loss\": 0.90,  # If it goes past 90% loss during the iteration, we don't want to waste time on a \"loser\".\n    \"csv_filename\": train_csv  # The variable that will be used to differentiate training and validation datasets\n}\n# Specific configuration keys that will be used during evaluation (only the overridden ones)\nenv_config_evaluation = {\n    \"max_allowed_loss\": 1.00,  # During validation runs we want to see how bad it would go. Even up to 100% loss.\n    \"csv_filename\": test_csv,  # The variable that will be used to differentiate training and validation datasets\n}\n\nsearch_alg = OptunaSearch()\nsearch_alg = ConcurrencyLimiter(search_alg, max_concurrent=4)\n\nscheduler = ASHAScheduler(\n    max_t=35,  # Max training iterations per trial\n    grace_period=5,  # Min iterations before early stopping\n)\n\nimport time\nstart = time.time()\n\n# Ray 2.x API: use tune.Tuner instead of tune.run\ntuner = tune.Tuner(\n    \"PPO\",\n    param_space={\n        \"env\": \"TradingEnv\",\n        \"env_config\": env_config_training,\n        \"log_level\": \"ERROR\",\n        \"framework\": \"torch\",\n        \"enable_rl_module_and_learner\": False,  # Use old API stack for model/lr_schedule support\n        \"enable_env_runner_and_connector_v2\": False,\n        \"ignore_env_runner_failures\": True,\n        \"num_env_runners\": 2,  # Ray 2.x: num_workers -> num_env_runners\n        \"num_gpus\": 0,\n        \"clip_rewards\": True,\n        \"lr\": LR,\n        \"lr_schedule\": [\n            [0, 1e-1],\n            [int(1e2), 1e-2],\n            [int(1e3), 1e-3],\n            [int(1e4), 1e-4],\n            [int(1e5), 1e-5],\n            [int(1e6), 1e-6],\n            [int(1e7), 1e-7]\n        ],\n        \"model\": {\n            \"use_attention\": True,\n            \"max_seq_len\": 10,\n            \"attention_num_transformer_units\": 1,\n            \"attention_dim\": 32,\n            \"attention_memory_inference\": 10,\n            \"attention_memory_training\": 10,\n            \"attention_num_heads\": 1,\n            \"attention_head_dim\": 32,\n            \"attention_position_wise_mlp_dim\": 32,\n        },\n        \"gamma\": GAMMA,\n        \"observation_filter\": \"MeanStdFilter\",\n        \"lambda_\": LAMBDA,  # Ray 2.x: \"lambda\" -> \"lambda_\"\n        \"num_envs_per_env_runner\": 20,  # Ray 2.x: num_envs_per_worker -> num_envs_per_env_runner\n        \"vf_share_layers\": True,\n        \"vf_loss_coeff\": VF_LOSS_COEFF,\n        \"entropy_coeff\": ENTROPY_COEFF,\n        \"num_sgd_iter\": 10,\n        \"evaluation_interval\": 1,  # Run evaluation on every iteration\n        \"evaluation_config\": {\n            \"env_config\": env_config_evaluation,  # The dictionary we built before\n            \"explore\": False,  # We don't want to explore during evaluation\n        },\n    },\n    tune_config=TuneConfig(\n        search_alg=search_alg,\n        scheduler=scheduler,\n        num_samples=1,  # Samples per hyperparameter combination\n        metric=checkpoint_metric,\n        mode=\"max\",\n    ),\n    run_config=RunConfig(\n        checkpoint_config=CheckpointConfig(\n            checkpoint_score_attribute=checkpoint_metric,\n            num_to_keep=10,\n        ),\n    ),\n)\n\n# Execute the tuning\nresults = tuner.fit()\n\ntaken = time.time() - start\nprint(f\"Time taken: {taken:.2f} seconds.\")\n\n# Get best result\nbest_result = results.get_best_result(metric=checkpoint_metric, mode=\"max\")\nprint(f\"Best config: {best_result.config}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30900354",
   "metadata": {},
   "outputs": [],
   "source": "# Plot episode reward mean across all trials\nax = None\nfor result in results:\n    if result.metrics_dataframe is not None:\n        df = result.metrics_dataframe\n        if 'env_runners/episode_reward_mean' in df.columns:\n            ax = df['env_runners/episode_reward_mean'].plot(ax=ax, legend=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56485836",
   "metadata": {},
   "outputs": [],
   "source": "# Ray 2.x API: Use PPO.from_checkpoint() instead of PPOTrainer\nfrom ray.rllib.algorithms.ppo import PPO\n\n# Get best checkpoint from results\nbest_result = results.get_best_result(metric=checkpoint_metric, mode='max')\ncheckpoint_path = best_result.checkpoint.path\n\nenv_config_validation = {\n    \"window_size\": 14,  # The number of past samples we want to look at (in hours)\n    \"reward_window_size\": 7,  # The number of hours we want to look at in the future to calculate the rewards based on the actions taken\n    \"max_allowed_loss\": 1.0,  # Allow 100% loss during evaluation\n    \"csv_filename\": valid_csv  # The variable that will be used to differentiate training and validation datasets\n}\n\n# Restore algorithm from checkpoint\nalgo = PPO.from_checkpoint(checkpoint_path)\n\n# Get config and update env_config for validation\nconfig = best_result.config.copy()\nconfig['env_config'] = env_config_validation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8cd97",
   "metadata": {},
   "outputs": [],
   "source": "# See how the model is wrapped by Attention\nalgo.get_policy().model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e6d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# Instantiate the environment\nenv = create_env(env_config_validation)\n\n# Run until episode ends\n# Gymnasium API: reset() returns (obs, info) tuple\nobs, info = env.reset()\n\n# Initialize state for attention model\nnum_transformers = config[\"model\"][\"attention_num_transformer_units\"]\nattention_dim = config[\"model\"][\"attention_dim\"]\nmemory = config[\"model\"][\"attention_memory_inference\"]\ninit_state = state = [\n    np.zeros([memory, attention_dim], np.float32)\n    for _ in range(num_transformers)\n]\n\ndone = truncated = False\ntotal_reward = 0\n\nprint(f\"TradingEnv with {config['env_config']}\")\nwhile not done and not truncated:\n    action, state_out, _ = algo.compute_single_action(obs, state)\n    # Gymnasium API: step() returns (obs, reward, terminated, truncated, info)\n    next_obs, reward, done, truncated, info = env.step(action)\n    obs = next_obs\n    total_reward += reward\n    state = [\n        np.concatenate([state[i], [state_out[i]]], axis=0)[1:]\n        for i in range(num_transformers)\n    ]\n\nprint(f\"Total reward in test episode: {total_reward}\")\nenv.render()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}