{"agent": "ppo", "states": {"type": "float", "shape": [5]}, "actions": {"type": "int", "shape": [], "num_values": 20}, "max_episode_timesteps": 2000, "network": [{"type": "dense", "size": 128, "activation": "tanh"}, {"type": "dense", "size": 64, "activation": "tanh"}, {"type": "dense", "size": 32, "activation": "tanh"}], "batch_size": 10, "update_frequency": "never", "learning_rate": 0.0001, "likelihood_ratio_clipping": 0.2, "discount": 0.99, "estimate_terminal": false, "critic_network": null, "critic_optimizer": null, "preprocessing": null, "exploration": 0.0, "variable_noise": 0.0, "l2_regularization": 0.0, "entropy_regularization": 0.0, "name": "agent", "device": null, "parallel_interactions": 1, "seed": null, "execution": null, "saver": {"directory": "agents/ppo"}, "summarizer": null, "recorder": null, "config": null}